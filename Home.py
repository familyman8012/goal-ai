import streamlit as st
import openai
from datetime import datetime
from database import add_goal, get_categories, add_category, add_recurring_goals
from config import OPENAI_API_KEY
from utils.llm_utils import LLMFactory, StreamHandler  # StreamHandler ì¶”ê°€
import uuid
from utils.date_utils import parse_weekdays, generate_recurring_dates

st.title("ëª©í‘œ ë‹¬ì„± GPT")
st.markdown(
    """
<p style='color: gray; font-size: 0.9em;'>
ğŸ’¡ ì‚¬ìš©ë²•: "ì»¤ë¦¬ì–´ì— ts ê³µë¶€ ì¶”ê°€í•´ì¤˜" ì™€ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ë³´ì„¸ìš”.
</p>
""",
    unsafe_allow_html=True,
)

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": f"""ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ ë¼ì´í”„ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. 
            í˜„ì¬ ë‚ ì§œëŠ” {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}ì…ë‹ˆë‹¤.
            
            ë‹¤ìŒ ì§€ì¹¨ì„ ë”°ë¼ì£¼ì„¸ìš”:
            1. ì‚¬ìš©ìì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ê³  ê³µê°í•˜ë©°, ëŒ€í™”ì˜ ë§¥ë½ì„ ì˜ ì´í•´í•©ë‹ˆë‹¤.
            2. ì‚¬ìš©ìì˜ ê³ ë¯¼ì´ë‚˜ ì´ì•¼ê¸°ì—ì„œ ëª©í‘œë¡œ ë°œì „ì‹œí‚¬ë§Œí•œ ë‚´ìš©ì´ ìˆë‹¤ë©´,
               ìì—°ìŠ¤ê²Œ "ê·¸ëŸ¼ [êµ¬ì²´ì ì¸ ëª©í‘œ]ë¥¼ ëª©í‘œë¡œ ì¶”ê°€í•´ë³´ëŠ” ê±´ ì–´ë– ì„¸ìš”?" ë¼ê³  ì œì•ˆí•©ë‹ˆë‹¤.
            3. ë‹¨, ëª¨ë“  ëŒ€í™”ì—ì„œ ëª©í‘œë¥¼ ì œì•ˆí•˜ì§€ ì•Šê³ , ëŒ€í™”ì˜ íë¦„ì„ ë³´ë©° ì ì ˆí•œ ë•Œì—ë§Œ ì œì•ˆí•©ë‹ˆë‹¤.
            4. ì‚¬ìš©ìê°€ ì§ì ‘ ëª©í‘œ ì¶”ê°€ë¥¼ ìš”ì²­í•  ë•ŒëŠ” ê³µê°ê³¼ ì§€ì§€ë¥¼ ë³´ë‚´ì£¼ì„¸ìš”.
            5. ìš©ìê°€ ì–¸ê¸‰í•˜ëŠ” ë‚ ì§œë¥¼ íŒŒì•…í•˜ì—¬ ëª©í‘œì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.
            
            ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì˜ ê¸°ì–µí•˜ê³  ì°¸ì¡°í•˜ì—¬, ë§ˆì¹˜ ì‹¤ì œ ìƒë‹´ì‚¬ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ì„¸ìš”.""",
        }
    ]

# ì´ì „ ë©”ì‹œì§€ í‘œì‹œ
for message in st.session_state.messages[1:]:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‚¬ìš©ì ì…ë ¥
if prompt := st.chat_input("AI ì»¨ì„¤í„´íŠ¸ì—ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ë‚´ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

# ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ ì¶”ê°€
st.sidebar.title("AI ëª¨ë¸ ì„¤ì •")
model_options = {
    "GPT-4o": "gpt-4o",
    "GPT-4o-mini": "gpt-4o-mini",
    "Claude-3.5-Sonnet": "claude-3-5-sonnet-20240620",
    "Claude-3-Haiku": "claude-3-haiku-20240307",
    "Gemini-Pro": "gemini-1.5-pro-latest",
    "Gemini-Flash": "gemini-1.5-flash-latest",
}

# ì…˜ ìƒíƒœì— ì„ íƒëœ ëª¨ë¸ ì €ì¥ (ê¸°ë³¸ê°’ì„ Claude-3-Haikuë¡œ ì„¤ì •)
if "selected_model" not in st.session_state:
    st.session_state.selected_model = model_options["Claude-3-Haiku"]

selected_model = st.sidebar.selectbox(
    "ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
    list(model_options.keys()),
    index=list(model_options.keys()).index(
        "Claude-3-Haiku"
    ),  # ê¸°ë³¸ê°’ì„ Gemini-Proë¡œ ì„¤ì •
)

# ì„ íƒëœ ëª¨ë¸ì´ ë³€ê²½ë˜ì—ˆì„ ë•Œë§Œ ì—…ë°ì´íŠ¸
if st.session_state.selected_model != model_options[selected_model]:
    st.session_state.selected_model = model_options[selected_model]

# ì„¸ì…˜ ID ìƒì„± (ì•± ì‹œì‘ì‹œ)
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

# ëª©í‘œ ì¶”ê°€ ì˜ë„ í™•ì¸ ë° ì¹´í…Œê³ ë¦¬ íŒŒì•…
if prompt:
    intent_system_prompt = """ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì—ì„œ ëª©í‘œ ì¶”ê°€ ì˜ë„ì™€ ì¹´í…Œê³ ë¦¬ë¥¼ íŒŒì•…í•˜ì„¸ìš”. 
'ì»¤ë¦¬ì–´ì— ê°œë°œê³µë¶€ ì¶”ê°€í•´ì¤˜' ë˜ëŠ” 'ê°œë°œê³µë¶€ ì¶”ê°€í•´ì¤˜' ì™€ ê°™ì€ í˜•ì‹ì´ë©´ 
'YES:ëª©í‘œë‚´ìš©:ì¹´í…Œê³ ë¦¬ëª…' í˜•ì‹ìœ¼ë¡œ, 
ì˜ˆë¥¼ ë“¤ì–´ 'ì»¤ë¦¬ì–´ì— ts ê³µë¶€ ì¶”ê°€í•´ì¤˜'ëŠ” 'YES:ts ê³µë¶€:ì»¤ë¦¬ì–´'ë¡œ, 
'ts ê³µë¶€ ì¶”ê°€í•´ì¤˜'ëŠ” 'YES:ts ê³µë¶€:ì „ì²´'ë¡œ,
'ë§¤ì£¼ í™” ëª© í† ìš”ì¼ì— ìš´ë™í•˜ê¸°'ì™€ ê°™ì€ ì •ê¸°ì ì¸ ì¼ì •ì€ 'RECURRING:ìš´ë™í•˜ê¸°:ì „ì²´'ë¡œ,
ëª©í‘œ ì¶”ê°€ ì˜ë„ê°€ ì—†ìœ¼ë©´ 'NO'ë¡œë§Œ ë‹µí•˜ì„¸ìš”. 
ë‹¨, 'ì¶”ê°€í•´ì¤˜'ë¼ëŠ” ë‹¨ì–´ê°€ ìˆì–´ì•¼ë§Œ ëª©í‘œ ì¶”ê°€ë¡œ ì¸ì‹í•©ë‹ˆë‹¤."""

    # single_get_response ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½ (ì»¨í…ìŠ¤íŠ¸ê°€ í•„ìš”ì—†ëŠ” ë‹¨ì¼ ìš”ì²­ì´ë¯€ë¡œ)
    intent_response = LLMFactory.single_get_response(
        st.session_state.selected_model, intent_system_prompt, prompt
    )

    if intent_response.startswith("RECURRING:"):
        parts = intent_response.split(":")
        goal_title = parts[1].strip()
        category_name = parts[2].strip()
        
        # ìš”ì¼ íŒŒì‹±
        weekdays = parse_weekdays(prompt)
        if weekdays:
            # ë‚ ì§œ ìƒì„±
            dates = generate_recurring_dates(weekdays)
            
            # ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
            category_id = None
            if category_name != "ì „ì²´":
                category_match = categories_df[categories_df["name"] == category_name]
                if not category_match.empty:
                    category_id = category_match.iloc[0]["id"]
                else:
                    new_category = add_category(category_name)
                    category_id = new_category.id
            
            # ì •ê¸° ëª©í‘œ ì¶”ê°€
            add_recurring_goals(
                title=goal_title,
                dates=dates,
                category_id=category_id
            )
            
            st.success(f"'{goal_title}'ì´(ê°€) {len(dates)}ê°œì˜ ë‚ ì§œì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
    elif intent_response.startswith("YES:"):
        parts = intent_response.split(":")
        goal_title = parts[1].strip()
        category_name = parts[2].strip()

        # ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
        categories_df = get_categories()
        category_id = None
        if category_name != "ì „ì²´":
            category_match = categories_df[
                categories_df["name"] == category_name
            ]
            if not category_match.empty:
                category_id = category_match.iloc[0]["id"]
            else:
                # ìƒˆ ì¹´í…Œê³ ë¦¬ ì¶”ê°€
                new_category = add_category(category_name)
                category_id = new_category.id

        # GPT ì‘ë‹µ
        chat_container = st.chat_message("assistant")
        stream_handler = StreamHandler(chat_container)

        # ë‚ ì§œ í™•ì¸ì„ ìœ„í•œ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        date_system_prompt = """
        ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì—ì„œ ëª©í‘œì˜ ì‹œì‘ì¼ê³¼ ì¢…ë£Œì¼ì„ íŒŒì•…í•˜ì„¸ìš”.
        ë‚ ì§œê°€ ì–¸ê¸‰ë˜ì–´ ìˆë‹¤ë©´ 'START:YYYY-MM-DD,END:YYYY-MM-DD' í˜•ì‹ìœ¼ë¡œ,
        ì—†ë‹¤ë©´ 'DEFAULT'ë¡œ ì‘ë‹µí•˜ì„¸ìš”.
        """

        date_response = LLMFactory.single_get_response(
            st.session_state.selected_model,
            date_system_prompt,
            prompt,
        )

        if date_response == "DEFAULT":
            start_date = datetime.now()
            end_date = start_date
        else:
            try:
                start_str = (
                    date_response.split(",")[0].replace("START:", "").strip()
                )
                end_str = (
                    date_response.split(",")[1].replace("END:", "").strip()
                )

                # ë‚ ì§œ í˜•ì‹ ê²€ì¦
                if not (
                    start_str.replace("-", "").isdigit()
                    and end_str.replace("-", "").isdigit()
                ):
                    start_date = datetime.now()
                    end_date = start_date
                else:
                    start_date = datetime.strptime(start_str, "%Y-%m-%d")
                    end_date = datetime.strptime(end_str, "%Y-%m-%d")
            except (ValueError, IndexError):
                start_date = datetime.now()
                end_date = start_date

        # ëª©í‘œ ì œëª© ì •ë¦¬
        clean_title = (
            goal_title.replace("ë‚´ì¼", "")
            .replace("ì˜¤ëŠ˜", "")
            .replace("ë‹¤ìŒì£¼", "")
            .replace("ë‹¤ìŒë‹¬", "")
            .replace("ë‹¤ìŒ ì£¼", "")
            .replace("ë‹¤ìŒ ë‹¬", "")
            .replace("ì´ë²ˆì£¼", "")
            .replace("ì´ë²ˆë‹¬", "")
            .replace("ì´ë²ˆ ì£¼", "")
            .replace("ì´ë²ˆ ë‹¬", "")
            .strip()
        )
        clean_title = (
            clean_title.replace("ì¶”ê°€í•´ì¤˜", "").strip()
        )

        # AI ì‘ë‹µ ìƒì„±
        assistant_response = LLMFactory.get_response(
            st.session_state.selected_model,
            st.session_state.messages[0]["content"],
            prompt,
            st.session_state.session_id,
            stream_handler=stream_handler,
        )

        st.session_state.messages.append(
            {"role": "assistant", "content": assistant_response}
        )

        # ëª©í‘œ ì¶”ê°€
        add_goal(
            title=clean_title,
            start_date=start_date,
            end_date=end_date,
            category_id=category_id,
        )
        st.success(
            f"'{clean_title}'ì´(ê°€) ëª©í‘œë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! ìƒì„¸ ë‚´ìš©ì€"
            " ëª©í‘œ ëª©ë¡ì—ì„œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )

    else:
        # ì¼ë°˜ ëŒ€í™”
        chat_container = st.chat_message("assistant")  # ì»¨í…Œì´ë„ˆë¥¼ ì§ì ‘ ìƒì„±
        stream_handler = StreamHandler(chat_container)
        assistant_response = LLMFactory.get_response(
            st.session_state.selected_model,
            st.session_state.messages[0]["content"],
            prompt,
            st.session_state.session_id,
            stream_handler=stream_handler,
        )

        st.session_state.messages.append(
            {"role": "assistant", "content": assistant_response}
        )
